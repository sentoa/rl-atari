# Prioritized Experience Replay for A2C

some intro and upcoming link to paper


# Files

|         Model       |File|Description|
|----------------|-------------------------------|-----------------------------|
|DQN with Experience Replay|`DQN.py`            |Deep Q-network algorithm from the Deepmind Paper            |
|         |`DQN_PROD.py`            |Since DQN hyperparams requires a lot of memory, this use a downscaled replay memory size for production.           |
|DQN with Priortized Experience Replay|`DQNPER.py`|From the Prioritzed Experience Replay Paper (need ref)|
|A2C |`A2C.py`|Actor-Critic Algorithm in vanilla form for Atari|
|A2C with Episodic Replay |`A2CER.py`|Actor-Critic Algorithm with Episodic Replay Memory|
|A2C with Prioritized Episodic Replay |`A2CPER.py`|Actor-Critic Algorithm with Prioritized Episodic Replay Memory|



## Requirements

TBD
